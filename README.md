<div align="center">
    <!--<img src="resources/images/eye.png">-->
</div>
<div> 
  <h1 align="center">DataScience</h1>
  <p>
    Here you will find the fruit of my dedication to the Data Science course in Python, where I have put my previous 
    knowledge into practice and acquired new skills in the fascinating world of Machine Learning.
  </p>
</div>

### Section 1: Data Cleaning

This section describes the process of reading data from various formats (CSV, TXT, XLS and URL) and its subsequent 
processing. The main goal is to combine the headers with the corresponding data and unify them into a single data set. 
Additionally, a technique is implemented to clean up missing values (NaN) by replacing them with defined values.

## Links
* [Dataset repository][dt] - Repository used during this project
* [CSV from URL][csv] - Resource used for the read_url.py exercise
* [Dotenv Vault][env] - Technology used to synchronize and manage versions of .env files

## Autor

* [Gustavo Hernandez][gh] 

--------

<div align="center"> 
  <p>
    Made with &hearts; by ghernandez  |   2020-2024
  </p>
</div>

<!-- Inicio de enlaces de este documento -->
[gh]: https://github.com/GustavoHdezH
[dt]: https://github.com/joanby/python-ml-course
[csv]: https://catalog.data.gov/dataset/air-quality
[env]: https://www.dotenv.org
<!-- Fin de enlaces de este documento -->